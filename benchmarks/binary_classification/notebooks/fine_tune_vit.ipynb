{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets transformers\n",
    "!pip install accelerate -U\n",
    "!pip install opencv-python\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'FunnyUpdate'\n",
    "name = 'vit_huge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'google/vit-huge-patch14-224-in21k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import cv2\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedaant/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)rocessor_config.json: 100%|██████████████████████████████████████████████| 160/160 [00:00<00:00, 169kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████████████████████████████████████████| 503/503 [00:00<00:00, 745kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViTImageProcessor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"image_processor_type\": \"ViTImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"height\": 224,\n",
       "    \"width\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "model_name_or_path = model_path\n",
    "image_processor  = AutoImageProcessor.from_pretrained(model_name_or_path)\n",
    "image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2081314194.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [2], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    huggingface_hub.login(hugging_face_login_key))\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "huggingface_hub.login(hugging_face_login_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|█████████████████████████████████████████████████████| 1516/1516 [00:00<00:00, 253147.74it/s]\n",
      "Downloading data files: 100%|████████████████████████████████████████████████████| 1516/1516 [00:00<00:00, 83984.69it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Generating train split: 1516 examples [00:00, 14150.33 examples/s]\n",
      "Resolving data files: 100%|███████████████████████████████████████████████████████| 483/483 [00:00<00:00, 242587.57it/s]\n",
      "Downloading data files: 100%|██████████████████████████████████████████████████████| 483/483 [00:00<00:00, 73946.88it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Generating train split: 483 examples [00:00, 17266.84 examples/s]\n",
      "Resolving data files: 100%|███████████████████████████████████████████████████████| 471/471 [00:00<00:00, 180215.03it/s]\n",
      "Downloading data files: 100%|██████████████████████████████████████████████████████| 471/471 [00:00<00:00, 52624.33it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Generating train split: 471 examples [00:00, 11254.71 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['image', 'label'],\n",
       "         num_rows: 1516\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['image', 'label'],\n",
       "         num_rows: 471\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['image', 'label'],\n",
       "         num_rows: 483\n",
       "     })\n",
       " }))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"imagefolder\", data_dir=\"NewDataset5/Train/\")\n",
    "valid_dataset = load_dataset(\"imagefolder\", data_dir=\"NewDataset5/Valid/\")\n",
    "test_dataset = load_dataset(\"imagefolder\", data_dir=\"NewDataset5/Test/\")\n",
    "train_dataset, test_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['image', 'label'],\n",
       "         num_rows: 1516\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['image', 'label'],\n",
       "         num_rows: 483\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['image', 'label'],\n",
       "         num_rows: 471\n",
       "     })\n",
       " }))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform(example_batch):\n",
    "    # Take a list of PIL images and turn them to pixel values\n",
    "    inputs = image_processor([x for x in example_batch['image']], return_tensors='pt')\n",
    "\n",
    "    # Don't forget to include the labels!\n",
    "    inputs['labels'] = example_batch['label']\n",
    "    return inputs\n",
    "\n",
    "prepared_train_ds = train_dataset.with_transform(transform)\n",
    "prepared_valid_ds = valid_dataset.with_transform(transform)\n",
    "prepared_test_ds = test_dataset.with_transform(transform)\n",
    "prepared_train_ds, prepared_valid_ds, prepared_test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch])\n",
    "    }\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "train_dataloader = DataLoader(prepared_train_ds['train'], batch_size = BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(prepared_valid_ds['train'], batch_size = BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(prepared_test_ds['train'], batch_size = BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|███████████████████████████████████████████████| 2.53G/2.53G [00:29<00:00, 85.2MB/s]\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-huge-patch14-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, ViTForImageClassification\n",
    "labels = prepared_train_ds['train'].features['label'].names\n",
    "model = ViTForImageClassification.from_pretrained(model_name_or_path, num_labels=len(labels), id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)}, ignore_mismatched_sizes=True)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.1, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T20:47:26.460001Z",
     "iopub.status.busy": "2023-07-06T20:47:26.459352Z",
     "iopub.status.idle": "2023-07-06T20:47:26.624921Z",
     "shell.execute_reply": "2023-07-06T20:47:26.623872Z",
     "shell.execute_reply.started": "2023-07-06T20:47:26.459955Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = #BATCH_SIZE\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./\"+name+project_name,\n",
    "  per_device_train_batch_size=BATCH_SIZE,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=4,\n",
    "  fp16=True,\n",
    "  save_steps=100,\n",
    "  eval_steps=100,\n",
    "  logging_steps=10,\n",
    "  learning_rate=1e-5,\n",
    "  save_total_limit=2,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=True,\n",
    "  report_to='tensorboard',\n",
    "  load_best_model_at_end=True,\n",
    "  optim='adamw_torch',\n",
    "  weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T20:48:33.333601Z",
     "iopub.status.busy": "2023-07-06T20:48:33.332914Z",
     "iopub.status.idle": "2023-07-06T20:48:43.002508Z",
     "shell.execute_reply": "2023-07-06T20:48:43.001452Z",
     "shell.execute_reply.started": "2023-07-06T20:48:33.333562Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_train_ds[\"train\"],\n",
    "    eval_dataset=prepared_valid_ds[\"train\"],\n",
    "    tokenizer=image_processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T20:48:43.004777Z",
     "iopub.status.busy": "2023-07-06T20:48:43.004145Z",
     "iopub.status.idle": "2023-07-06T20:54:14.601753Z",
     "shell.execute_reply": "2023-07-06T20:54:14.600702Z",
     "shell.execute_reply.started": "2023-07-06T20:48:43.004743Z"
    }
   },
   "outputs": [],
   "source": [
    "train_results = trainer.train()\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T20:54:23.795181Z",
     "iopub.status.busy": "2023-07-06T20:54:23.794817Z",
     "iopub.status.idle": "2023-07-06T20:54:53.043749Z",
     "shell.execute_reply": "2023-07-06T20:54:53.042808Z",
     "shell.execute_reply.started": "2023-07-06T20:54:23.795153Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = trainer.predict(prepared_test_ds['train'])\n",
    "trainer.log_metrics(\"test\", metrics.metrics)\n",
    "trainer.save_metrics(\"test\", metrics.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T20:55:20.845017Z",
     "iopub.status.busy": "2023-07-06T20:55:20.844510Z",
     "iopub.status.idle": "2023-07-06T20:55:20.874859Z",
     "shell.execute_reply": "2023-07-06T20:55:20.873945Z",
     "shell.execute_reply.started": "2023-07-06T20:55:20.844978Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_tensor = torch.tensor(metrics.predictions)\n",
    "preds = torch.sigmoid(predictions_tensor)\n",
    "print(preds.shape)\n",
    "preds = torch.argmax(preds, dim=1)\n",
    "preds, preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T20:55:24.793719Z",
     "iopub.status.busy": "2023-07-06T20:55:24.793189Z",
     "iopub.status.idle": "2023-07-06T20:55:24.799788Z",
     "shell.execute_reply": "2023-07-06T20:55:24.798666Z",
     "shell.execute_reply.started": "2023-07-06T20:55:24.793676Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T20:55:25.769434Z",
     "iopub.status.busy": "2023-07-06T20:55:25.769055Z",
     "iopub.status.idle": "2023-07-06T20:55:25.806526Z",
     "shell.execute_reply": "2023-07-06T20:55:25.805616Z",
     "shell.execute_reply.started": "2023-07-06T20:55:25.769405Z"
    }
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(preds, metrics.label_ids), f1_score(preds, metrics.label_ids))\n",
    "pd.DataFrame(confusion_matrix(preds, metrics.label_ids), columns=['Test Funny', 'Test Not Funny'], index=['Pred Funny','Pred Not Funny'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T20:57:12.696001Z",
     "iopub.status.busy": "2023-07-06T20:57:12.695635Z",
     "iopub.status.idle": "2023-07-06T20:58:27.635949Z",
     "shell.execute_reply": "2023-07-06T20:58:27.634855Z",
     "shell.execute_reply.started": "2023-07-06T20:57:12.695966Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = trainer.predict(prepared_train_ds['train'])\n",
    "predictions_tensor = torch.tensor(metrics.predictions)\n",
    "preds = torch.sigmoid(predictions_tensor)\n",
    "print(preds.shape)\n",
    "preds = torch.argmax(preds, dim=1)\n",
    "preds, preds.shape\n",
    "print(accuracy_score(preds, metrics.label_ids), f1_score(preds, metrics.label_ids))\n",
    "pd.DataFrame(confusion_matrix(preds, metrics.label_ids), columns=['Train Funny', 'Train Not Funny'], index=['Pred Funny','Pred Not Funny'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T20:56:47.204965Z",
     "iopub.status.busy": "2023-07-06T20:56:47.204543Z",
     "iopub.status.idle": "2023-07-06T20:57:12.693479Z",
     "shell.execute_reply": "2023-07-06T20:57:12.692304Z",
     "shell.execute_reply.started": "2023-07-06T20:56:47.204936Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = trainer.predict(prepared_valid_ds['train'])\n",
    "predictions_tensor = torch.tensor(metrics.predictions)\n",
    "preds = torch.sigmoid(predictions_tensor)\n",
    "print(preds.shape)\n",
    "preds = torch.argmax(preds, dim=1)\n",
    "preds, preds.shape\n",
    "print(accuracy_score(preds, metrics.label_ids), f1_score(preds, metrics.label_ids))\n",
    "pd.DataFrame(confusion_matrix(preds, metrics.label_ids), columns=['Valid Funny', 'Valid Not Funny'], index=['Pred Funny','Pred Not Funny'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
